{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asl model ver1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MWY1eHstAInEGJD9dmFspxSeqOvRNXPn",
      "authorship_tag": "ABX9TyMORo8zHld58yA/Fpdvp6H8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhresnaPanduI/ASL-Model/blob/main/asl_model_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0RovYNGt-l"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDEJVLs-CFMR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTt9KW8xGyr8",
        "outputId": "af822a73-641e-4f4a-d45b-4188429566f8"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwAN_MFYgphN"
      },
      "source": [
        "Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbWwtZgagpWC"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/Datasets/own asl/Train'\n",
        "test_dir = '/content/drive/MyDrive/Datasets/own asl/test'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFFtaGmQhjxB"
      },
      "source": [
        "Number of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAArNpeNhiQo",
        "outputId": "8e299d16-4a42-472f-e32a-6fec79624191"
      },
      "source": [
        "import os\n",
        "\n",
        "categories = os.listdir(train_dir)\n",
        "categoriest = os.listdir(test_dir)\n",
        "print(len(categories))\n",
        "print(len(categoriest))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sszs1nnliJW5"
      },
      "source": [
        "train_data_gen = ImageDataGenerator(\n",
        "                              rescale=1/255)\n",
        "\n",
        "test_data_gen = ImageDataGenerator(\n",
        "                              rescale=1/255)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQzqdZ8iiJ4g",
        "outputId": "ab387b53-2cd6-42ec-ec66-549a4bc1c843"
      },
      "source": [
        "train_gen = train_data_gen.flow_from_directory(train_dir,\n",
        "                                         target_size=(224,224),\n",
        "                                         class_mode=\"categorical\",\n",
        "                                         color_mode=\"rgb\",\n",
        "                                         shuffle=True,\n",
        "                                         batch_size=32)\n",
        "\n",
        "val_gen = test_data_gen.flow_from_directory(test_dir,\n",
        "                                          target_size=(224,224),\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          shuffle=True,\n",
        "                                          batch_size=32,)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1171 images belonging to 29 classes.\n",
            "Found 289 images belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHo_h8zHpFOW"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXw-9BXSf6aM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cae2e61-ab8e-4c31-e770-8c1b7d061584"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(29, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29)                37149     \n",
            "=================================================================\n",
            "Total params: 2,295,133\n",
            "Trainable params: 2,261,021\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-kmp1VbjrZw"
      },
      "source": [
        "Unfreeze some layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3jPUd3ejjzI"
      },
      "source": [
        "NUM_LAYERS = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "feature_extractor.trainable = True\n",
        "    \n",
        "for layer in model.layers[-NUM_LAYERS:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxm7dAcmj2XQ"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj9k46kaj4Qv",
        "outputId": "847b6621-258d-4e87-dc5e-b683b45e870c"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_gen,\n",
        "                 epochs = 10,\n",
        "                 validation_data = val_gen)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 23s 426ms/step - loss: 0.4161 - accuracy: 0.9175 - val_loss: 1.5601 - val_accuracy: 0.6920\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 15s 402ms/step - loss: 0.1962 - accuracy: 0.9817 - val_loss: 12.8974 - val_accuracy: 0.0969\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 15s 402ms/step - loss: 0.0984 - accuracy: 0.9994 - val_loss: 1.2362 - val_accuracy: 0.7543\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 15s 404ms/step - loss: 0.1184 - accuracy: 0.9949 - val_loss: 0.8173 - val_accuracy: 0.7958\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 15s 404ms/step - loss: 0.1132 - accuracy: 0.9961 - val_loss: 4.7583 - val_accuracy: 0.4706\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 15s 404ms/step - loss: 0.1234 - accuracy: 0.9945 - val_loss: 0.4853 - val_accuracy: 0.9031\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 0.0995 - accuracy: 0.9979 - val_loss: 1.6809 - val_accuracy: 0.6540\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 15s 401ms/step - loss: 0.2090 - accuracy: 0.9689 - val_loss: 0.9071 - val_accuracy: 0.8547\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 15s 405ms/step - loss: 0.1398 - accuracy: 0.9870 - val_loss: 3.1296 - val_accuracy: 0.7232\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 15s 399ms/step - loss: 0.1035 - accuracy: 0.9986 - val_loss: 1.5321 - val_accuracy: 0.7197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3zvlW-JtBsY"
      },
      "source": [
        "ASL_SAVED_MODEL = \"asl_saved_model\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVb8PBEvy4X",
        "outputId": "6bba9c79-5684-42a0-99a9-ee640671a9d2"
      },
      "source": [
        "tf.saved_model.save(model, ASL_SAVED_MODEL)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: asl_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: asl_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMFvv8xwDRH",
        "outputId": "d64d4c02-70cf-450d-946b-03358167aee3"
      },
      "source": [
        "%%bash -s $ASL_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['keras_layer_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_keras_layer_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 29)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsd1kpSowArP",
        "outputId": "7d47e960-8dff-45eb-8820-d5a3abe8bf78"
      },
      "source": [
        "loaded = tf.saved_model.load(ASL_SAVED_MODEL)\n",
        "\n",
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['serving_default']\n",
            "((), {'keras_layer_input': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_layer_input')})\n",
            "{'dense': TensorSpec(shape=(None, 29), dtype=tf.float32, name='dense')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQX8JzRwaK1"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(ASL_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWdArgZwjJd"
      },
      "source": [
        "tflite_model_file = 'converted_asl_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_LgtI4Ux-ZU"
      },
      "source": [
        "Create file to save labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkCsRnuiw21l"
      },
      "source": [
        "class_names = ['a', 'b', 'c', 'd', 'e', 'del', 'f', 'g', 'h',\n",
        "               'i', 'j', 'k', 'l', 'm', 'n', 'nothing', 'o', 'p',\n",
        "               'q', 'r', 's', 'space', 't', 'u', 'v', 'w', 'x', \n",
        "               'y', 'z']\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oNbPPUpozBM8",
        "outputId": "074538b8-3dd5-448c-f80d-61f91489de2b"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_asl_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c812c7e9-5fc0-4e9a-adf2-808618b4684c\", \"converted_asl_model.tflite\", 2664320)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7d26094e-f84a-4a68-baf0-124567bf5207\", \"labels.txt\", 69)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXZydXC8zwgz"
      },
      "source": [
        ""
      ]
    }
  ]
}