{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asl model ver1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MWY1eHstAInEGJD9dmFspxSeqOvRNXPn",
      "authorship_tag": "ABX9TyPuwmjDwyfzA7X1q1VTvZLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhresnaPanduI/ASL-Model/blob/main/asl_model_ver1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0RovYNGt-l"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDEJVLs-CFMR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTt9KW8xGyr8",
        "outputId": "8f05455e-002d-4756-ae42-c04eec48335c"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwAN_MFYgphN"
      },
      "source": [
        "Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbWwtZgagpWC"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/Datasets/own asl/Train'\n",
        "test_dir = '/content/drive/MyDrive/Datasets/own asl/test'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFFtaGmQhjxB"
      },
      "source": [
        "Number of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAArNpeNhiQo",
        "outputId": "26392c72-cee4-4951-d7d4-f68f35658975"
      },
      "source": [
        "import os\n",
        "\n",
        "categories = os.listdir(train_dir)\n",
        "categoriest = os.listdir(test_dir)\n",
        "print(len(categories))\n",
        "print(len(categoriest))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sszs1nnliJW5"
      },
      "source": [
        "train_data_gen = ImageDataGenerator(\n",
        "                              rescale=1/255)\n",
        "\n",
        "test_data_gen = ImageDataGenerator(\n",
        "                              rescale=1/255)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQzqdZ8iiJ4g",
        "outputId": "2972c44c-a890-43ef-9862-9c8d10ec1e28"
      },
      "source": [
        "train_gen = train_data_gen.flow_from_directory(train_dir,\n",
        "                                         target_size=(224,224),\n",
        "                                         class_mode=\"categorical\",\n",
        "                                         color_mode=\"rgb\",\n",
        "                                         shuffle=True,\n",
        "                                         batch_size=32)\n",
        "\n",
        "val_gen = test_data_gen.flow_from_directory(test_dir,\n",
        "                                          target_size=(224,224),\n",
        "                                          class_mode=\"categorical\",\n",
        "                                          color_mode=\"rgb\",\n",
        "                                          shuffle=True,\n",
        "                                          batch_size=32,)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1171 images belonging to 29 classes.\n",
            "Found 289 images belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHo_h8zHpFOW"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXw-9BXSf6aM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2277884-668a-4402-f568-42f817eb1ab7"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(29, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 29)                37149     \n",
            "=================================================================\n",
            "Total params: 2,295,133\n",
            "Trainable params: 2,261,021\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-kmp1VbjrZw"
      },
      "source": [
        "Unfreeze some layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3jPUd3ejjzI"
      },
      "source": [
        "NUM_LAYERS = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "feature_extractor.trainable = True\n",
        "    \n",
        "for layer in model.layers[-NUM_LAYERS:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxm7dAcmj2XQ"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj9k46kaj4Qv",
        "outputId": "0cf00a8a-34ae-4ecf-8447-62946cef702a"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_gen,\n",
        "                 epochs = 10,\n",
        "                 validation_data = val_gen)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 462s 11s/step - loss: 1.5193 - accuracy: 0.6450 - val_loss: 2.8999 - val_accuracy: 0.3979\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.2244 - accuracy: 0.9650 - val_loss: 9.0491 - val_accuracy: 0.1730\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.3457 - accuracy: 0.9255 - val_loss: 2.3735 - val_accuracy: 0.5467\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 9s 233ms/step - loss: 0.1571 - accuracy: 0.9861 - val_loss: 1.1629 - val_accuracy: 0.6955\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.1268 - accuracy: 0.9933 - val_loss: 1.0543 - val_accuracy: 0.7163\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 0.1416 - accuracy: 0.9871 - val_loss: 6.9471 - val_accuracy: 0.2837\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 0.1363 - accuracy: 0.9789 - val_loss: 0.9253 - val_accuracy: 0.8097\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 0.1271 - accuracy: 0.9933 - val_loss: 2.3383 - val_accuracy: 0.5640\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9273\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 9s 244ms/step - loss: 0.1593 - accuracy: 0.9816 - val_loss: 1.8947 - val_accuracy: 0.6782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3zvlW-JtBsY"
      },
      "source": [
        "ASL_SAVED_MODEL = \"asl_saved_model\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVb8PBEvy4X",
        "outputId": "769021ba-3991-48aa-bf58-d293c0932e9f"
      },
      "source": [
        "tf.saved_model.save(model, ASL_SAVED_MODEL)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: asl_saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: asl_saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYzvAiNUwlI-",
        "outputId": "334dd903-2dcd-491e-b53c-dad67212685d"
      },
      "source": [
        "%%bash -s $ASL_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['keras_layer_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_keras_layer_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 29)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIGJCLrD3P25"
      },
      "source": [
        "def representative_dataset_gen():\n",
        "  for i in range(50):\n",
        "    image = tf.random.uniform([1, 224, 224, 3])\n",
        "    yield [image]\n",
        "\n",
        "imported = tf.saved_model.load(ASL_SAVED_MODEL)\n",
        "\n",
        "concrete_func = imported.signatures[\"serving_default\"]\n",
        "\n",
        "concrete_func.inputs[0].set_shape([1, 224, 224, 3])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] \n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "converter.inference_input_type = tf.uint8\n",
        "\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model = converter.convert() "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWdArgZwjJd"
      },
      "source": [
        "tflite_model_file = 'quantized_asl_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_LgtI4Ux-ZU"
      },
      "source": [
        "Create file to save labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkCsRnuiw21l"
      },
      "source": [
        "class_names = ['a', 'b', 'c', 'd', 'e', 'del', 'f', 'g', 'h',\n",
        "               'i', 'j', 'k', 'l', 'm', 'n', 'nothing', 'o', 'p',\n",
        "               'q', 'r', 's', 'space', 't', 'u', 'v', 'w', 'x', \n",
        "               'y', 'z']\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNbPPUpozBM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f3f59a0a-7d7a-4cc6-b609-f7a1eec279e4"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('quantized_asl_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a1782aa3-2f49-4a7f-aa40-280a083e1537\", \"quantized_asl_model.tflite\", 2955136)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ce275c2e-9666-4534-82d3-0dfde48e8961\", \"labels.txt\", 69)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXZydXC8zwgz"
      },
      "source": [
        ""
      ]
    }
  ]
}